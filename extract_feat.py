import argparse
import os
import json
import pickle 
from tqdm import tqdm

parser = argparse.ArgumentParser(description="aaaaaaaaaaaaaaaaaaaaa")
parser.add_argument("-z", "--base_path", type=str, help="path to git project evaluate_model",default="/media/data/flowers/evaluate_model/")
parser.add_argument("-m", "--arg_model_id", type=int, help=" model")
parser.add_argument("-f", "--arg_limited_trainset", type=str, help=" model",default="full")

args = parser.parse_args()

os.environ['HF_DATASETS_CACHE'] = args.base_path+"hf/datasets"
os.environ['TRANSFORMERS_CACHE'] = args.base_path+"hf/models"
os.environ['TRANSFORMERS_OFFLINE'] = "1"
os.environ['TOKENIZERS_PARALLELISM'] = "True"

import numpy as np
import torch
from transformers import pipeline
list_name_model=[args.base_path+"hf/models/"+"WizardCoder-1B-V1.0",args.base_path+"hf/models/"+"WizardCoder-3B-V1.0",args.base_path+"hf/models/"+"WizardCoder-Python-7B-V1.0",args.base_path+"hf/models/"+"WizardCoder-Python-13B-V1.0",args.base_path+"hf/models/"+"WizardCoder-15B-V1.0"]
model_id=list_name_model[args.arg_model_id]

print("\n=============================\n")
print(model_id)
print("\n=============================\n")

from transformers import BitsAndBytesConfig
quantization_config = BitsAndBytesConfig(
   load_in_4bit=True,
   bnb_4bit_compute_dtype=torch.float16
)



# /!\ set that
# limited_trainset=True # data generated by expe with 3 first example from trainset or full trainset
if args.arg_limited_trainset=="limited":
    option="limited_trainset"

if args.arg_limited_trainset=="full":
    option="full_trainset"

feature_extractor = pipeline("feature-extraction", model=model_id,device_map="auto",quantization_config=quantization_config)
name_model=model_id.split("/")[-1]
list_all_seed=[]
with torch.no_grad():
    text_test = "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{instruction}"
    len_base_prompt = feature_extractor(text_test,return_tensors = "pt").size(1)
    
    list_seed=["1","2","3"]
    for seed in list_seed:
        if seed=="1":
            path_rd_gen= "run_saved/"+option+"/maps_1_rd_gen.json"
            path_elm="run_saved/"+option+"/maps_1_elm.json"
            path_elm_nlp="run_saved/"+option+"/maps_1_elm_NLP.json"
            path_img_rd="run_saved/"+option+"/maps_1_imgep_random.json"
            path_imgp_smart="run_saved/"+option+"/maps_1_imgep_smart.json"

        if seed=="2":
            path_rd_gen= "run_saved/"+option+"/maps_2_rd_gen.json"
            path_elm="run_saved/"+option+"/maps_2_elm.json"
            path_elm_nlp="run_saved/"+option+"/maps_2_elm_NLP.json"
            path_img_rd="run_saved/"+option+"/maps_2_imgep_random.json"
            path_imgp_smart="run_saved/"+option+"/maps_2_imgep_smart.json"

        if seed=="3":
            path_rd_gen= "run_saved/"+option+"/maps_3_rd_gen.json"
            path_elm="run_saved/"+option+"/maps_3_elm.json"
            path_elm_nlp="run_saved/"+option+"/maps_3_elm_NLP.json"
            path_img_rd="run_saved/"+option+"/maps_3_imgep_random.json"
            path_imgp_smart="run_saved/"+option+"/maps_3_imgep_smart.json"

        list_name=["rd_gen","elm","elm_NLP","imgep_random","imgep_smart"]

        list_path=[path_rd_gen, path_elm,path_elm_nlp,path_img_rd,path_imgp_smart]
        list_all_embeddings = []
        for path in list_path:
            with open(args.base_path+path, 'r') as f:
                data = json.load(f)
            list_emb_path_i=[]
            list_puzzl= [puzz["program_str"] for puzz in data]
            for puz in tqdm(list_puzzl):
                text= "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{instruction}"

                new_text=text.format(instruction=puz)
                feat_out=feature_extractor(new_text,return_tensors = "pt")[0][len_base_prompt:]
                # print(feat_out)
                out= feat_out.numpy().mean(axis=0) 
                # print(out)
                list_emb_path_i.append([out])
            list_emb_path_i=np.array(list_emb_path_i)
            list_all_embeddings.append(list_emb_path_i)
        list_all_seed.append(list_all_embeddings)
        print(list_all_seed)
    with open(args.base_path+"save_feat/"+name_model+option+'_feat.pkl', 'wb') as f:
        pickle.dump(list_all_seed, f)